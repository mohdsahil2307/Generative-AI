{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"The meaning of NLP is Natural Language Processing (NLP) which is a fascinating and rapidly evolving field that intersects computer science, artificial intelligence, and linguistics.\n",
    "NLP focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
    "With the increasing volume of text data generated every day, from social media posts to research articles, NLP has become an essential tool for extracting valuable insights and automating various tasks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of NLP is Natural Language Processing (NLP) which is a fascinating and rapidly evolving field that intersects computer science, artificial intelligence, and linguistics.\n",
      "NLP focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
      "With the increasing volume of text data generated every day, from social media posts to research articles, NLP has become an essential tool for extracting valuable insights and automating various tasks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we convert the sentence into paragraph : \n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The meaning of NLP is Natural Language Processing (NLP) which is a fascinating and rapidly evolving field that intersects computer science, artificial intelligence, and linguistics.', 'NLP focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language in a way that is both meaningful and useful.', 'With the increasing volume of text data generated every day, from social media posts to research articles, NLP has become an essential tool for extracting valuable insights and automating various tasks.']\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome,to Krish Naik's NLP Tutorials.\n",
      "Please do watch the entire course!\n",
      "to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'meaning',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'is',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'which',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fascinating',\n",
       " 'and',\n",
       " 'rapidly',\n",
       " 'evolving',\n",
       " 'field',\n",
       " 'that',\n",
       " 'intersects',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " ',',\n",
       " 'and',\n",
       " 'linguistics',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language',\n",
       " ',',\n",
       " 'enabling',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'is',\n",
       " 'both',\n",
       " 'meaningful',\n",
       " 'and',\n",
       " 'useful',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'increasing',\n",
       " 'volume',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data',\n",
       " 'generated',\n",
       " 'every',\n",
       " 'day',\n",
       " ',',\n",
       " 'from',\n",
       " 'social',\n",
       " 'media',\n",
       " 'posts',\n",
       " 'to',\n",
       " 'research',\n",
       " 'articles',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'become',\n",
       " 'an',\n",
       " 'essential',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'extracting',\n",
       " 'valuable',\n",
       " 'insights',\n",
       " 'and',\n",
       " 'automating',\n",
       " 'various',\n",
       " 'tasks',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "vocab = word_tokenize(corpus)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization \n",
    "## Paragraph-->words\n",
    "## sentence--->words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'Tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Welcome', ',', 'to', 'Krish', 'Naik', \"'s\", 'NLP', 'Tutorials', '.']\n",
      "['Please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
      "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'\",\n",
       " 's',\n",
       " 'NLP',\n",
       " 'Tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'Tutorials.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
